#!/usr/bin/env python3
"""
å¿ƒè„å››è…”åˆ†å‰²è®­ç»ƒä¸»è„šæœ¬
é›†æˆSAMã€PANetå’Œå¿ƒè„ç‰¹å®šç‰¹å¾çš„ç«¯åˆ°ç«¯è®­ç»ƒ
æ”¯æŒä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼šå†»ç»“SAMä¸»å¹² + åˆ†å±‚å­¦ä¹ ç‡å¾®è°ƒ

ğŸš€ å¿«é€Ÿå¼€å§‹ç¤ºä¾‹ï¼š
# åŸºç¡€è®­ç»ƒï¼ˆæ¨èï¼Œè‡ªåŠ¨ä¸¤é˜¶æ®µè®­ç»ƒï¼‰
python scripts/train_cardiac.py --data_root database/database_nifti --model_type cardiac_sam

# å®Œæ•´å‚æ•°è®­ç»ƒ
python scripts/train_cardiac.py --data_root database/database_nifti --model_type cardiac_sam --epochs 50 --batch_size 1 --image_size 256 256 --accumulate_steps 8 --use_checkpoint --num_workers 0 --learning_rate 1e-5 --weight_decay 1e-4

# è‡ªå®šä¹‰ä¸¤é˜¶æ®µè®­ç»ƒ
python scripts/train_cardiac.py --data_root database/database_nifti --model_type cardiac_sam --epochs 100 --stage1_epochs 10 --stage1_learning_rate 2e-4

ğŸ“‹ ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼š
é˜¶æ®µä¸€ï¼šå†»ç»“SAMä¸»å¹²ï¼Œå¿«é€Ÿè®­ç»ƒPANetå’Œåˆ†å‰²å¤´ï¼ˆ5-10 epochsï¼‰
é˜¶æ®µäºŒï¼šè§£å†»SAMä¸»å¹²ï¼Œåˆ†å±‚å­¦ä¹ ç‡å¾®è°ƒï¼ˆå‰©ä½™epochsï¼‰

ğŸ¯ æ¨èé…ç½®ï¼š
- epochs: 50-100
- batch_size: 1-2
- accumulate_steps: 8
- image_size: 256x256 æˆ– 512x512
- learning_rate: 1e-5ï¼ˆè‡ªåŠ¨è°ƒæ•´ï¼‰
- weight_decay: 1e-4
"""

import os
import sys
import argparse
import torch
import torch.nn as nn
import numpy as np
from typing import Dict, Any
import json
import logging
from datetime import datetime
import warnings

# æŠ‘åˆ¶æ‰€æœ‰nibabelè­¦å‘Š
warnings.filterwarnings("ignore", category=UserWarning, module="nibabel")
warnings.filterwarnings("ignore", message="pixdim.*qfac.*should be 1.*")
warnings.filterwarnings("ignore", category=FutureWarning, module="torch")

# ç›´æ¥å±è”½nibabelçš„INFOæ—¥å¿—
import logging
logging.getLogger('nibabel').setLevel(logging.WARNING)

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from configs.cardiac_config import CardiacConfig
from configs.model_config import ModelConfig
from models.cardiac_sam import CardiacSAM
from models.cardiac_panet import CardiacPANet
from base.data_processing import create_cardiac_dataloader
from base.training_core import create_sam_trainer, create_panet_trainer
from utils.visualization import create_visualization_utils
from utils.metrics import create_cardiac_metrics
from utils.losses import CardiacLoss, ExtremeImbalanceLoss, GradientMonitor, online_hard_example_mining


def setup_logging(log_dir: str) -> logging.Logger:
    """è®¾ç½®æ—¥å¿—"""
    os.makedirs(log_dir, exist_ok=True)
    
    # åˆ›å»ºæ—¥å¿—æ–‡ä»¶å
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    log_file = os.path.join(log_dir, f'training_{timestamp}.log')
    
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler(sys.stdout)
        ]
    )
    
    logger = logging.getLogger(__name__)
    logger.debug(f"æ—¥å¿—æ–‡ä»¶: {log_file}")
    
    return logger


def setup_device(device: str) -> torch.device:
    """è®¾ç½®è®­ç»ƒè®¾å¤‡"""
    if device == 'auto':
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    if device == 'cuda' and not torch.cuda.is_available():
        print("è­¦å‘Š: CUDAä¸å¯ç”¨ï¼Œä½¿ç”¨CPU")
        device = 'cpu'
    
        # è®¾å¤‡ä¿¡æ¯å·²é™é»˜è®¾ç½®
    
    return torch.device(device)


def create_model(model_type: str, config: Dict[str, Any], device: torch.device) -> nn.Module:
    """åˆ›å»ºæ¨¡å‹"""
    # é™é»˜åˆ›å»ºæ¨¡å‹
    if model_type == 'cardiac_sam':
        model = CardiacSAM(config=config)
    elif model_type == 'cardiac_panet':
        model = CardiacPANet(
            num_classes=config['num_classes'],
            feature_dim=config['feature_dim'],
            use_sam_features=config.get('use_sam_features', True)
        )
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}")
    
    return model.to(device)


def setup_two_stage_training(model: nn.Module, config: Dict[str, Any], device: torch.device):
    """
    è®¾ç½®ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥
    
    é˜¶æ®µä¸€ï¼šå†»ç»“SAMä¸»å¹²ï¼Œå¿«é€Ÿè®­ç»ƒPANetå’Œåˆ†å‰²å¤´
    é˜¶æ®µäºŒï¼šè§£å†»SAMï¼Œä½¿ç”¨åˆ†å±‚å­¦ä¹ ç‡è¿›è¡Œå¾®è°ƒ
    """
    # é™é»˜è®¾ç½®ä¸¤é˜¶æ®µè®­ç»ƒ
    if hasattr(model, 'sam_model') and hasattr(model.sam_model, 'image_encoder'):
        for param in model.sam_model.image_encoder.parameters():
            param.requires_grad = False
        config['stage1_learning_rate'] = config.get('stage1_learning_rate', 1e-4)
        config['stage1_epochs'] = config.get('stage1_epochs', 5)
        return True
    else:
        return False


def create_trainer(model: nn.Module, 
                  model_type: str,
                  train_loader, 
                  val_loader, 
                  config: Dict[str, Any], 
                  device: torch.device,
                  checkpoint_dir: str,
                  criterion: nn.Module = None):
    """åˆ›å»ºè®­ç»ƒå™¨"""
    if model_type == 'cardiac_sam':
        trainer = create_sam_trainer(
            model=model,
            train_loader=train_loader,
            val_loader=val_loader,
            device=device,
            save_dir=checkpoint_dir,
            num_epochs=config.get('epochs', 100),
            use_amp=config.get('use_amp', True),
            early_stopping_patience=config.get('early_stopping_patience', 15),  # æ”¾å®½æ—©åœæœŸé™åˆ°15
            criterion=criterion  # ä¼ é€’å¤–éƒ¨åˆ›å»ºçš„æŸå¤±å‡½æ•°
        )
    elif model_type == 'cardiac_panet':
        trainer = create_panet_trainer(
            model=model,
            train_loader=train_loader,
            val_loader=val_loader,
            device=device,
            learning_rate=config.get('learning_rate', 1e-4),
            weight_decay=config.get('weight_decay', 1e-4),
            num_epochs=config.get('epochs', 20),
            save_dir=checkpoint_dir
        )
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}")
    
    return trainer


def execute_classification_training(model, train_loader, val_loader, config, device, logger, output_dir):
    """æ‰§è¡Œä¸‰é˜¶æ®µåˆ†ç±»è®­ç»ƒç­–ç•¥"""
    
    # ä¸‰é˜¶æ®µåˆ†ç±»è®­ç»ƒé…ç½® - ä¼˜åŒ–æ¸è¿›å¼æå‡ç­–ç•¥
    # åŠ¨æ€è®¡ç®—ä¸‰ä¸ªé˜¶æ®µçš„æ¯”ä¾‹ï¼Œç¡®ä¿æ¯ä¸ªé˜¶æ®µæœ‰è¶³å¤Ÿçš„è®­ç»ƒæ—¶é—´
    total_epochs = config.get('epochs', 50)
    stage1_ratio = 15 / 50  # é˜¶æ®µ1æ¯”ä¾‹ï¼š20/65 â‰ˆ 0.31 (æ›´å¤šæ—¶é—´å»ºç«‹åŸºç¡€)
    stage2_ratio = 15 / 50  # é˜¶æ®µ2æ¯”ä¾‹ï¼š20/65 â‰ˆ 0.31 (å……åˆ†å­¦ä¹ å·¦å³å¿ƒåŒºåˆ†)
    stage3_ratio = 20 / 50  # é˜¶æ®µ3æ¯”ä¾‹ï¼š25/65 â‰ˆ 0.38 (ç²¾ç»†åˆ†å‰²éœ€è¦æ›´å¤šæ—¶é—´)
    
    stage1_epochs = max(3, int(total_epochs * stage1_ratio))  # è‡³å°‘3ä¸ªepoch
    stage2_epochs = max(3, int(total_epochs * stage2_ratio))  # è‡³å°‘3ä¸ªepoch
    stage3_epochs = max(5, total_epochs - stage1_epochs - stage2_epochs)  # è‡³å°‘5ä¸ªepoch
    
    classification_stages = [
        {
            'name': 'é˜¶æ®µ1: èƒŒæ™¯vså¿ƒè„æ•´ä½“',
            'num_classes': 2,
            'epochs': stage1_epochs,
            'freeze_sam': True,
            'learning_rate': 5e-4,  # è¿›ä¸€æ­¥æé«˜å­¦ä¹ ç‡ï¼Œå¿«é€Ÿå»ºç«‹åŸºç¡€
            'class_weights': [0.01, 10.0],  # å¤§å¹…æå‡å¿ƒè„æƒé‡ï¼ŒåŸºäº78:1çš„ä¸å¹³è¡¡æ¯”ä¾‹
            'description': 'è®©æ¨¡å‹å…ˆå­¦ä¼š"å“ªé‡Œæ˜¯å¿ƒè„"ï¼Œå»ºç«‹åŸºç¡€åˆ†å‰²èƒ½åŠ›',
            'expected_dice_range': (0.1, 0.4),  # æœŸæœ›DiceèŒƒå›´
            'warmup_epochs': 2  # é¢„çƒ­è½®æ•°
        },
        {
            'name': 'é˜¶æ®µ2: å››è…”ç²—åˆ†ï¼ˆå·¦å¿ƒvså³å¿ƒï¼‰',
            'num_classes': 3,
            'epochs': stage2_epochs,
            'freeze_sam': 'partial',  # è§£å†»æœ€å2ä¸ªTransformer Block
            'learning_rate': 3e-4,  # æé«˜å­¦ä¹ ç‡ï¼ŒåŠ å¼ºå·¦å³å¿ƒåŒºåˆ†
            'class_weights': [0.01, 8.0, 8.0],  # å¤§å¹…æå‡å·¦å³å¿ƒæƒé‡ï¼ŒåŸºäº160:1:1çš„ä¸å¹³è¡¡æ¯”ä¾‹
            'description': 'åŒºåˆ†å·¦å³å¿ƒç³»ç»Ÿï¼Œå»ºç«‹å¯¹ç§°æ€§æ„ŸçŸ¥ï¼Œåˆ©ç”¨å¿ƒè„å·¦å³å¯¹ç§°æ€§',
            'expected_dice_range': (0.3, 0.6),  # æœŸæœ›DiceèŒƒå›´
            'warmup_epochs': 1  # é¢„çƒ­è½®æ•°
        },
        {
            'name': 'é˜¶æ®µ3: å®Œæ•´äº”ç±»ç²¾ç»†åˆ†å‰²',
            'num_classes': 5,
            'epochs': stage3_epochs,
            'freeze_sam': False,  # è§£å†»æ•´ä¸ªSAM
            'learning_rate': 1e-4,  # æé«˜å­¦ä¹ ç‡ï¼ŒåŠ å¼ºç²¾ç»†åˆ†å‰²
            'class_weights': [0.01, 15.0, 20.0, 12.0, 10.0],  # åŸºäºå®é™…æ•°æ®åˆ†å¸ƒè°ƒæ•´æƒé‡
            'description': 'ç²¾ç»†åˆ†å‰²LVã€RVã€LAã€RAã€èƒŒæ™¯ï¼Œè”åˆè®­ç»ƒSAM+PANet',
            'expected_dice_range': (0.5, 0.8),  # æœŸæœ›DiceèŒƒå›´
            'warmup_epochs': 1  # é¢„çƒ­è½®æ•°
        }
    ]
    
    all_results = {}
    
    for stage_idx, stage in enumerate(classification_stages):
        # é™é»˜è®¾ç½®é˜¶æ®µä¿¡æ¯ï¼Œåªä¿ç•™å…³é”®è¾“å‡º
        print(f"é˜¶æ®µ{stage_idx + 1}: {stage['name']}")
        print(f"æœŸæœ›DiceèŒƒå›´: {stage['expected_dice_range'][0]:.1f} - {stage['expected_dice_range'][1]:.1f}")
        print(f"{stage['num_classes']}ç±»åˆ†å‰², {stage['epochs']}è½®è®­ç»ƒ")
        
        # è°ƒæ•´æ¨¡å‹è¾“å‡ºç±»åˆ«æ•° - åªåœ¨ç±»åˆ«æ•°çœŸæ­£æ”¹å˜æ—¶æ‰é‡å»ºå¤´éƒ¨
        in_features = model.cardiac_head[-1].in_channels
        current_classes = model.cardiac_head[-1].out_channels
        
        if current_classes != stage['num_classes']:
            # ä¿å­˜å½“å‰å¤´éƒ¨æƒé‡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            old_head_weight = None
            old_head_bias = None
            if hasattr(model.cardiac_head[-1], 'weight') and model.cardiac_head[-1].weight is not None:
                old_head_weight = model.cardiac_head[-1].weight.data.clone()
                old_head_bias = model.cardiac_head[-1].bias.data.clone()
            
            # åˆ›å»ºæ–°çš„å¤´éƒ¨
            model.cardiac_head[-1] = nn.Conv2d(in_features, stage['num_classes'], 1).to(device)
            
            # å°è¯•ç»§æ‰¿æƒé‡ - æ”¹è¿›æƒé‡ç»§æ‰¿ç­–ç•¥
            if old_head_weight is not None:
                new_weight = model.cardiac_head[-1].weight.data
                new_bias = model.cardiac_head[-1].bias.data
                
                # å¦‚æœæ–°ç±»åˆ«æ•° >= æ—§ç±»åˆ«æ•°ï¼Œå¯ä»¥éƒ¨åˆ†ç»§æ‰¿æƒé‡
                if new_weight.shape[0] >= old_head_weight.shape[0]:
                    # ç»§æ‰¿ç°æœ‰æƒé‡
                    new_weight[:old_head_weight.shape[0]] = old_head_weight
                    new_bias[:old_head_bias.shape[0]] = old_head_bias
                    
                    # å¯¹äºæ–°å¢çš„ç±»åˆ«ï¼Œä½¿ç”¨ç°æœ‰æƒé‡çš„å¹³å‡å€¼è¿›è¡Œåˆå§‹åŒ–
                    if new_weight.shape[0] > old_head_weight.shape[0]:
                        avg_weight = old_head_weight.mean(dim=0, keepdim=True)
                        avg_bias = old_head_bias.mean()
                        for i in range(old_head_weight.shape[0], new_weight.shape[0]):
                            new_weight[i] = avg_weight + torch.randn_like(avg_weight) * 0.1
                            new_bias[i] = avg_bias + torch.randn_like(avg_bias) * 0.1
                    
                    # é™é»˜ç»§æ‰¿æƒé‡
                else:
                    # å¦‚æœæ–°ç±»åˆ«æ•° < æ—§ç±»åˆ«æ•°ï¼Œé€‰æ‹©æœ€é‡è¦çš„ç±»åˆ«æƒé‡
                    if stage_idx == 1:  # é˜¶æ®µ2ï¼šé€‰æ‹©èƒŒæ™¯å’Œå¿ƒè„æƒé‡
                        new_weight[0] = old_head_weight[0]  # èƒŒæ™¯
                        new_weight[1] = old_head_weight[1:].mean(dim=0)  # å¿ƒè„æ•´ä½“
                        new_bias[0] = old_head_bias[0]
                        new_bias[1] = old_head_bias[1:].mean()
                    else:  # å…¶ä»–æƒ…å†µï¼Œé€‰æ‹©å‰å‡ ä¸ªç±»åˆ«
                        new_weight[:] = old_head_weight[:new_weight.shape[0]]
                        new_bias[:] = old_head_bias[:new_bias.shape[0]]
                    # é™é»˜é€‰æ‹©æ€§ç»§æ‰¿æƒé‡
            
            # **å…³é”®ä¿®å¤ï¼šæ›´æ–°æ¨¡å‹çš„num_classeså±æ€§**
            model.num_classes = stage['num_classes']
        else:
            # é™é»˜ä¿æŒå½“å‰å¤´éƒ¨
            pass
        
        # é‡æ–°åˆ›å»ºæŸå¤±å‡½æ•°ä»¥åŒ¹é…æ–°çš„ç±»åˆ«æ•°
        class_weights = torch.tensor(stage['class_weights']).to(device)
        criterion = ExtremeImbalanceLoss(
            num_classes=stage['num_classes'],
            alpha=0.25,
            gamma=2.0,
            dice_weight=1.0,
            focal_weight=1.0,
            use_class_weights=True,
            use_focal=True,
            use_dice=True
        ).to(device)
        # é™é»˜åˆ›å»ºæŸå¤±å‡½æ•°
        
        # åº”ç”¨SAMå†»ç»“ç­–ç•¥ - é™é»˜æ‰§è¡Œ
        if stage['freeze_sam'] == True:
            # å†»ç»“æ‰€æœ‰SAMå‚æ•°
            for param in model.sam_model.image_encoder.parameters():
                param.requires_grad = False
        elif stage['freeze_sam'] == 'partial':
            # åªè§£å†»æœ€å2ä¸ªTransformer Block
            if hasattr(model.sam_model.image_encoder, 'blocks'):
                total_blocks = len(model.sam_model.image_encoder.blocks)
                for i, block in enumerate(model.sam_model.image_encoder.blocks):
                    for param in block.parameters():
                        param.requires_grad = i >= (total_blocks - 2)  # è§£å†»æœ€å2å±‚
        else:
            # è§£å†»æ•´ä¸ªSAMä¸»å¹²ï¼ˆå‰70%å±‚ï¼‰
            if hasattr(model.sam_model.image_encoder, 'blocks'):
                total_blocks = len(model.sam_model.image_encoder.blocks)
                freeze_blocks = int(total_blocks * 0.3)  # åªå†»ç»“å‰30%
                for i, block in enumerate(model.sam_model.image_encoder.blocks):
                    for param in block.parameters():
                        param.requires_grad = i >= freeze_blocks
        
        # åˆ›å»ºä¼˜åŒ–å™¨ - æ·»åŠ å­¦ä¹ ç‡é¢„çƒ­
        trainable_params = [p for p in model.parameters() if p.requires_grad]
        optimizer = torch.optim.AdamW(trainable_params, lr=stage['learning_rate'], weight_decay=1e-4)
        
        # å­¦ä¹ ç‡é¢„çƒ­è°ƒåº¦å™¨
        warmup_epochs = stage['warmup_epochs']
        if warmup_epochs > 0:
            def lr_lambda(epoch):
                if epoch < warmup_epochs:
                    return epoch / warmup_epochs  # çº¿æ€§é¢„çƒ­
                else:
                    return 1.0  # æ­£å¸¸å­¦ä¹ ç‡
            scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)
        else:
            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=stage['epochs'])
        
        # æŸå¤±å‡½æ•°å·²åœ¨ä¸Šé¢é‡æ–°åˆ›å»º
        
        # æ ‡ç­¾è½¬æ¢å‡½æ•° - ä¿®å¤æ ‡ç­¾æ˜ å°„é—®é¢˜
        def convert_labels_for_stage(labels, num_classes):
            if num_classes == 2:
                # èƒŒæ™¯(0) vs å¿ƒè„æ•´ä½“(1)ï¼šåˆå¹¶æ‰€æœ‰å¿ƒè„ç»“æ„
                # ç¡®ä¿æ ‡ç­¾å€¼åœ¨[0, 1]èŒƒå›´å†…
                converted = (labels > 0).long()
                return torch.clamp(converted, 0, 1)
            elif num_classes == 3:
                # èƒŒæ™¯(0) + å·¦å¿ƒ(1) + å³å¿ƒ(2)
                new_labels = labels.clone()
                # å·¦å¿ƒå®¤(1) + å·¦å¿ƒæˆ¿(3) -> å·¦å¿ƒ(1)
                new_labels[labels == 1] = 1  # å·¦å¿ƒå®¤ -> å·¦å¿ƒ
                new_labels[labels == 3] = 1  # å·¦å¿ƒæˆ¿ -> å·¦å¿ƒ
                # å³å¿ƒå®¤(2) + å³å¿ƒæˆ¿(4) -> å³å¿ƒ(2)
                new_labels[labels == 2] = 2  # å³å¿ƒå®¤ -> å³å¿ƒ
                new_labels[labels == 4] = 2  # å³å¿ƒæˆ¿ -> å³å¿ƒ
                # ç¡®ä¿æ ‡ç­¾å€¼åœ¨[0, 2]èŒƒå›´å†…
                return torch.clamp(new_labels, 0, 2)
            else:
                # 5ç±»ï¼šä¿æŒåŸæ ·ï¼Œç¡®ä¿æ ‡ç­¾å€¼åœ¨[0, 4]èŒƒå›´å†…
                return torch.clamp(labels, 0, 4)
        
        # ä½¿ç”¨åŸæœ‰çš„è®­ç»ƒå™¨æ¡†æ¶ï¼Œä½†ä¿®æ”¹æŸå¤±å‡½æ•°å’Œæ ‡ç­¾è½¬æ¢
        from base.training_core import SAMTrainer
        
        # åˆ›å»ºåŒ…è£…çš„æ•°æ®åŠ è½½å™¨
        class ClassificationDataLoader:
            def __init__(self, original_loader, num_classes):
                self.original_loader = original_loader
                self.num_classes = num_classes
                self.dataset = original_loader.dataset
            
            def __iter__(self):
                for batch in self.original_loader:
                    if isinstance(batch, dict):
                        images = batch['image']
                        labels = convert_labels_for_stage(batch['label'], self.num_classes)
                        yield {'image': images, 'label': labels}
                    else:
                        images, labels = batch
                        labels = convert_labels_for_stage(labels, self.num_classes)
                        yield images, labels
            
            def __len__(self):
                return len(self.original_loader)
        
        # åŒ…è£…æ•°æ®åŠ è½½å™¨
        wrapped_train_loader = ClassificationDataLoader(train_loader, stage['num_classes'])
        wrapped_val_loader = ClassificationDataLoader(val_loader, stage['num_classes'])
        
        # åˆ›å»ºé˜¶æ®µä¸“ç”¨è®­ç»ƒå™¨ï¼Œç›´æ¥ä¼ é€’æŸå¤±å‡½æ•°
        stage_trainer = SAMTrainer(
            model=model,
            train_loader=wrapped_train_loader,
            val_loader=wrapped_val_loader,
            device=device,
            learning_rate=stage['learning_rate'],
            num_epochs=stage['epochs'],
            save_dir=output_dir,
            use_amp=True,
            accumulation_steps=4,
            early_stopping_patience=15,
            criterion=criterion  # ç›´æ¥ä¼ é€’æŸå¤±å‡½æ•°
        )
        
        # **å…³é”®ä¿®å¤ï¼šæ›´æ–°è®­ç»ƒå™¨çš„ç±»åˆ«æ•°ä¿¡æ¯**
        stage_trainer.num_classes = stage['num_classes']
        
        # æ›¿æ¢ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
        stage_trainer.optimizer = optimizer
        stage_trainer.scheduler = scheduler
        
        # é™é»˜å¼€å§‹è®­ç»ƒ
        best_dice_so_far = 0.0
        dice_history = []
        
        # è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯ï¼Œä¿ç•™è¿›åº¦æ¡å’Œå…³é”®è¾“å‡º
        for epoch in range(stage['epochs']):
            # è®­ç»ƒä¸€ä¸ªepoch
            train_metrics = stage_trainer.train_epoch(epoch)
            
            # éªŒè¯ä¸€ä¸ªepoch
            val_metrics = stage_trainer.validate_epoch(epoch)
            
            # æ›´æ–°å­¦ä¹ ç‡
            stage_trainer.scheduler.step()
            
            # è®°å½•Diceå†å²
            current_dice = val_metrics.get('mean_dice', 0)
            dice_history.append(current_dice)
            
            # æ›´æ–°æœ€ä½³Dice
            if current_dice > best_dice_so_far:
                best_dice_so_far = current_dice
            
            # æ‰“å°è®­ç»ƒè¿›åº¦å’Œå…³é”®æ•°æ®
            print(f"Epoch {epoch+1}/{stage['epochs']}: "
                  f"Train Loss: {train_metrics.get('train_loss', 0):.4f}, "
                  f"Val Loss: {val_metrics.get('val_loss', 0):.4f}, "
                  f"Val Dice: {current_dice:.4f}")
        
        # ä¿å­˜é˜¶æ®µç»“æœ
        stage_results = {
            'final_train_loss': train_metrics.get('train_loss', 0),
            'final_val_loss': val_metrics.get('val_loss', 0),
            'final_val_dice': current_dice,
            'best_val_dice': best_dice_so_far,
            'dice_history': dice_history,
            'expected_range': stage['expected_dice_range'],
            'achieved_target': best_dice_so_far >= stage['expected_dice_range'][0]
        }
        
        # ä¿å­˜é˜¶æ®µæ£€æŸ¥ç‚¹
        stage_checkpoint_path = os.path.join(output_dir, f'classification_stage_{stage_idx + 1}_best.pth')
        torch.save({
            'stage': stage_idx + 1,
            'stage_name': stage['name'],
            'num_classes': stage['num_classes'],
            'model_state_dict': model.state_dict(),
            'results': stage_results
        }, stage_checkpoint_path)
        
        all_results[f'classification_stage_{stage_idx + 1}'] = stage_results
        
        # é˜¶æ®µå®Œæˆæ€»ç»“ - åªä¿ç•™å…³é”®è¾“å‡º
        print(f"é˜¶æ®µ{stage_idx + 1}å®Œæˆ! æœ€ä½³Dice: {best_dice_so_far:.4f}")
        
        # é˜¶æ®µé—´è¿‡æ¸¡æç¤º - åªä¿ç•™å…³é”®è¾“å‡º
        if stage_idx < len(classification_stages) - 1:
            next_stage = classification_stages[stage_idx + 1]
            print(f"å‡†å¤‡è¿›å…¥é˜¶æ®µ{stage_idx + 2}: {next_stage['name']}")
            print(f"æœŸæœ›DiceèŒƒå›´: {next_stage['expected_dice_range'][0]:.1f} - {next_stage['expected_dice_range'][1]:.1f}")
    
    logger.debug("ä¸‰é˜¶æ®µåˆ†ç±»è®­ç»ƒå®Œæˆï¼")
    return all_results


def execute_two_stage_training(trainer, config: Dict[str, Any], logger):
    """
    æ‰§è¡Œä¸¤é˜¶æ®µè®­ç»ƒ
    
    é˜¶æ®µä¸€ï¼šå†»ç»“SAMä¸»å¹²ï¼Œå¿«é€Ÿè®­ç»ƒ
    é˜¶æ®µäºŒï¼šè§£å†»SAMï¼Œåˆ†å±‚å­¦ä¹ ç‡å¾®è°ƒ
    """
    print("\nå¼€å§‹ä¸¤é˜¶æ®µè®­ç»ƒ...")
    
    # é˜¶æ®µä¸€ï¼šå†»ç»“è®­ç»ƒ
    stage1_epochs = config.get('stage1_epochs', 5)
    print(f"\né˜¶æ®µä¸€ï¼šå†»ç»“SAMä¸»å¹²è®­ç»ƒ ({stage1_epochs} epochs)")
    print("ç›®æ ‡ï¼šè®©PANetå’Œåˆ†å‰²å¤´å¿«é€Ÿé€‚åº”ä»»åŠ¡")
    
    # è®¾ç½®é˜¶æ®µä¸€çš„å­¦ä¹ ç‡
    original_lr = trainer.optimizer.param_groups[0]['lr']
    stage1_lr = config.get('stage1_learning_rate', 1e-4)
    
    # æ›´æ–°å­¦ä¹ ç‡
    for param_group in trainer.optimizer.param_groups:
        param_group['lr'] = stage1_lr
    
    print(f"  - é˜¶æ®µä¸€å­¦ä¹ ç‡: {stage1_lr}")
    print(f"  - åŸå§‹å­¦ä¹ ç‡: {original_lr}")
    
    # æ‰§è¡Œé˜¶æ®µä¸€è®­ç»ƒ
    # ä¸´æ—¶ä¿®æ”¹è®­ç»ƒå™¨çš„epochså±æ€§
    original_epochs = trainer.num_epochs
    trainer.num_epochs = stage1_epochs
    stage1_results = trainer.train()
    # æ¢å¤åŸå§‹num_epochs
    trainer.num_epochs = original_epochs
    
    print(f"é˜¶æ®µä¸€è®­ç»ƒå®Œæˆï¼")
    
    # å®‰å…¨åœ°è·å–å’Œæ‰“å°ç»“æœ
    final_train_loss = stage1_results.get('final_train_loss', 'N/A')
    final_val_loss = stage1_results.get('final_val_loss', 'N/A')
    final_val_dice = stage1_results.get('final_val_dice', 'N/A')
    
    if isinstance(final_train_loss, (int, float)):
        print(f"  - æœ€ç»ˆè®­ç»ƒæŸå¤±: {final_train_loss:.4f}")
    else:
        print(f"  - æœ€ç»ˆè®­ç»ƒæŸå¤±: {final_train_loss}")
    
    if isinstance(final_val_loss, (int, float)):
        print(f"  - æœ€ç»ˆéªŒè¯æŸå¤±: {final_val_loss:.4f}")
    else:
        print(f"  - æœ€ç»ˆéªŒè¯æŸå¤±: {final_val_loss}")
    
    if isinstance(final_val_dice, (int, float)):
        print(f"  - æœ€ç»ˆéªŒè¯Dice: {final_val_dice:.4f}")
    else:
        print(f"  - æœ€ç»ˆéªŒè¯Dice: {final_val_dice}")
    
    # é˜¶æ®µäºŒï¼šè§£å†»å¾®è°ƒ
    print(f"\né˜¶æ®µäºŒï¼šè§£å†»SAMä¸»å¹²ï¼Œåˆ†å±‚å­¦ä¹ ç‡å¾®è°ƒ")
    print("ç›®æ ‡ï¼šè®©æ•´ä¸ªæ¨¡å‹ååŒä¼˜åŒ–ï¼Œè¿½æ±‚æ›´é«˜ç²¾åº¦")
    
    # è§£å†»SAMçš„image_encoder
    if hasattr(trainer.model, 'sam_model') and hasattr(trainer.model.sam_model, 'image_encoder'):
        for param in trainer.model.sam_model.image_encoder.parameters():
            param.requires_grad = True
        print("SAM Image Encoderå·²è§£å†»")
    
    # è®¾ç½®åˆ†å±‚å­¦ä¹ ç‡
    stage2_lr_sam = config.get('stage2_lr_sam', 1e-6)      # SAMä¸»å¹²ï¼šæä½å­¦ä¹ ç‡
    stage2_lr_panet = config.get('stage2_lr_panet', 1e-5)  # PANetï¼šä¸­ç­‰å­¦ä¹ ç‡
    stage2_lr_head = config.get('stage2_lr_head', 1e-5)    # åˆ†å‰²å¤´ï¼šä¸­ç­‰å­¦ä¹ ç‡
    
    # åˆ›å»ºåˆ†å±‚å­¦ä¹ ç‡ä¼˜åŒ–å™¨
    param_groups = []
    
    # SAMä¸»å¹²å‚æ•°ç»„
    if hasattr(trainer.model, 'sam_model') and hasattr(trainer.model.sam_model, 'image_encoder'):
        sam_params = list(trainer.model.sam_model.image_encoder.parameters())
        param_groups.append({'params': sam_params, 'lr': stage2_lr_sam})
        print(f"  - SAMä¸»å¹²å­¦ä¹ ç‡: {stage2_lr_sam}")
    
    # PANetå‚æ•°ç»„
    if hasattr(trainer.model, 'panet_fusion'):
        panet_params = list(trainer.model.panet_fusion.parameters())
        param_groups.append({'params': panet_params, 'lr': stage2_lr_panet})
        print(f"  - PANetå­¦ä¹ ç‡: {stage2_lr_panet}")
    
    # åˆ†å‰²å¤´å‚æ•°ç»„
    if hasattr(trainer.model, 'cardiac_head'):
        head_params = list(trainer.model.cardiac_head.parameters())
        param_groups.append({'params': head_params, 'lr': stage2_lr_head})
        print(f"  - åˆ†å‰²å¤´å­¦ä¹ ç‡: {stage2_lr_head}")
    
    # å…¶ä»–å‚æ•°ä½¿ç”¨é»˜è®¤å­¦ä¹ ç‡
    other_params = []
    for name, param in trainer.model.named_parameters():
        if not any(name.startswith(prefix) for prefix in ['sam_model.image_encoder', 'panet_fusion', 'cardiac_head']):
            other_params.append(param)
    
    if other_params:
        param_groups.append({'params': other_params, 'lr': original_lr})
        print(f"  - å…¶ä»–å‚æ•°å­¦ä¹ ç‡: {original_lr}")
    
    # åˆ›å»ºæ–°çš„ä¼˜åŒ–å™¨
    trainer.optimizer = torch.optim.AdamW(
        param_groups,
        weight_decay=config.get('weight_decay', 3e-5)
    )
    
    # é‡æ–°åˆ›å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨
    trainer.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        trainer.optimizer,
        T_max=trainer.num_epochs,
        eta_min=1e-7
    )
    
    print(" åˆ†å±‚å­¦ä¹ ç‡ä¼˜åŒ–å™¨å·²è®¾ç½®")
    
    # è®¡ç®—å‰©ä½™è®­ç»ƒè½®æ•°
    total_epochs = config.get('epochs', 100)
    remaining_epochs = total_epochs - stage1_epochs
    
    print(f"  - å‰©ä½™è®­ç»ƒè½®æ•°: {remaining_epochs}")
    
    # æ‰§è¡Œé˜¶æ®µäºŒè®­ç»ƒ
    # ä¸´æ—¶ä¿®æ”¹è®­ç»ƒå™¨çš„num_epochså±æ€§
    original_epochs = trainer.num_epochs
    trainer.num_epochs = remaining_epochs
    stage2_results = trainer.train()
    # æ¢å¤åŸå§‹num_epochs
    trainer.num_epochs = original_epochs
    
    print(f"âœ… é˜¶æ®µäºŒè®­ç»ƒå®Œæˆï¼")
    
    # å®‰å…¨åœ°è·å–å’Œæ‰“å°ç»“æœ
    final_train_loss = stage2_results.get('final_train_loss', 'N/A')
    final_val_loss = stage2_results.get('final_val_loss', 'N/A')
    final_val_dice = stage2_results.get('final_val_dice', 'N/A')
    
    if isinstance(final_train_loss, (int, float)):
        print(f"  - æœ€ç»ˆè®­ç»ƒæŸå¤±: {final_train_loss:.4f}")
    else:
        print(f"  - æœ€ç»ˆè®­ç»ƒæŸå¤±: {final_train_loss}")
    
    if isinstance(final_val_loss, (int, float)):
        print(f"  - æœ€ç»ˆéªŒè¯æŸå¤±: {final_val_loss:.4f}")
    else:
        print(f"  - æœ€ç»ˆéªŒè¯æŸå¤±: {final_val_loss}")
    
    if isinstance(final_val_dice, (int, float)):
        print(f"  - æœ€ç»ˆéªŒè¯Dice: {final_val_dice:.4f}")
    else:
        print(f"  - æœ€ç»ˆéªŒè¯Dice: {final_val_dice}")
    
    # åˆå¹¶ç»“æœ
    combined_results = {
        'stage1': stage1_results,
        'stage2': stage2_results,
        'total_epochs': total_epochs,
        'stage1_epochs': stage1_epochs,
        'stage2_epochs': remaining_epochs
    }
    
    return combined_results


def verify_fixes(model: nn.Module, device: torch.device, logger) -> Dict[str, bool]:
    """é™é»˜éªŒè¯å…³é”®é—®é¢˜æ˜¯å¦å·²è§£å†³"""
    verification_results = {}
    
    try:
        # ç®€å•éªŒè¯ç‰¹å¾ç»´åº¦
        test_input = torch.randn(1, 3, 512, 512).to(device)
        with torch.no_grad():
            model.eval()
            outputs = model(test_input)
            verification_results['feature_dimension_fix'] = 'cardiac_logits' in outputs and outputs['cardiac_logits'].shape == (1, 5, 512, 512)
        
        # ç®€å•éªŒè¯æŸå¤±å‡½æ•°
        class_weights = torch.tensor([0.20, 2.50, 2.80, 2.20, 2.00]).to(device)
        cardiac_loss = CardiacLoss(weights=class_weights).to(device)
        test_pred = torch.randn(1, 5, 64, 64).to(device)
        test_target = torch.randint(0, 5, (1, 64, 64)).to(device)
        loss = cardiac_loss(test_pred, test_target)
        verification_results['class_imbalance_fix'] = torch.isfinite(loss) and loss.item() > 0
        
        # ç®€å•éªŒè¯æ¢¯åº¦
        model.train()
        outputs = model(test_input)
        loss = cardiac_loss(outputs['cardiac_logits'], torch.randint(0, 5, (1, 512, 512)).to(device))
        loss.backward()
        grad_monitor = GradientMonitor(model)
        grad_norm = grad_monitor.check_gradients()
        verification_results['gradient_monitoring_fix'] = grad_norm > 0 and torch.isfinite(torch.tensor(grad_norm))
        model.zero_grad()
        
        verification_results['all_fixes_verified'] = all(verification_results.values())
        
    except Exception as e:
        logger.error(f"éªŒè¯å¤±è´¥: {e}")
        verification_results = {'all_fixes_verified': False}
    
    return verification_results


def main():
    """ä¸»å‡½æ•°"""

    
    parser = argparse.ArgumentParser(description='å¿ƒè„å››è…”åˆ†å‰²è®­ç»ƒ - æ”¯æŒä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥')
    
    # åŸºæœ¬å‚æ•°
    parser.add_argument('--model_type', type=str, default='cardiac_sam',
                       choices=['cardiac_sam', 'cardiac_panet'],
                       help='æ¨¡å‹ç±»å‹')
    parser.add_argument('--use_classification_training', type=bool, default=True,
                       help='ä½¿ç”¨ä¸‰é˜¶æ®µåˆ†ç±»è®­ç»ƒç­–ç•¥ï¼ˆèƒŒæ™¯vså¿ƒè„â†’å·¦å¿ƒvså³å¿ƒâ†’å®Œæ•´äº”ç±»ï¼‰ï¼ˆé»˜è®¤å¯ç”¨ï¼‰')
    parser.add_argument('--data_root', type=str, required=True,
                       help='æ•°æ®æ ¹ç›®å½•')
    parser.add_argument('--output_dir', type=str, default='shared/outputs',
                       help='è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ï¼šshared/outputsï¼‰')
    parser.add_argument('--device', type=str, default='auto',
                       choices=['auto', 'cpu', 'cuda'],
                       help='è®­ç»ƒè®¾å¤‡')
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument('--epochs', type=int, default=50,
                       help='æ€»è®­ç»ƒè½®æ•°ï¼ˆæ¨èï¼š50-100ï¼‰')
    parser.add_argument('--batch_size', type=int, default=2,
                       help='æ‰¹æ¬¡å¤§å°ï¼ˆæ¨èï¼š2-4ï¼Œå¹³è¡¡è®­ç»ƒæ•ˆç‡å’Œæ˜¾å­˜ï¼‰')
    parser.add_argument('--accumulate_steps', type=int, default=4,
                       help='æ¢¯åº¦ç´¯ç§¯æ­¥æ•°ï¼ˆæ¨èï¼š4ï¼Œæœ‰æ•ˆæ‰¹æ¬¡å¤§å° = batch_size Ã— accumulate_stepsï¼‰')
    parser.add_argument('--learning_rate', type=float, default=1e-5,
                       help='åŸºç¡€å­¦ä¹ ç‡ï¼ˆæ¨èï¼š1e-5ï¼Œä¸¤é˜¶æ®µè®­ç»ƒä¼šè‡ªåŠ¨è°ƒæ•´ï¼‰')
    parser.add_argument('--weight_decay', type=float, default=1e-4,
                       help='æƒé‡è¡°å‡ï¼ˆæ¨èï¼š1e-4ï¼Œé€‚ä¸­çš„æ­£åˆ™åŒ–ï¼‰')
    parser.add_argument('--use_amp', action='store_true', default=True,
                       help='ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆèŠ‚çœå†…å­˜ï¼Œä½†å¯èƒ½å½±å“ç¨³å®šæ€§ï¼‰')
    parser.add_argument('--use_checkpoint', action='store_true', default=True,
                       help='ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼ˆæ¨èå¯ç”¨ï¼ŒèŠ‚çœå†…å­˜ï¼‰')
    
    # ä¸¤é˜¶æ®µè®­ç»ƒå‚æ•°ï¼ˆè‡ªåŠ¨ä¼˜åŒ–ï¼Œé€šå¸¸æ— éœ€æ‰‹åŠ¨è°ƒæ•´ï¼‰
    parser.add_argument('--use_two_stage', action='store_true', default=True,
                       help='ä½¿ç”¨ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼ˆå¼ºçƒˆæ¨èï¼Œè‡ªåŠ¨å†»ç»“SAMä¸»å¹²+åˆ†å±‚å­¦ä¹ ç‡ï¼‰')
    parser.add_argument('--stage1_epochs', type=int, default=5,
                       help='é˜¶æ®µä¸€è®­ç»ƒè½®æ•°ï¼ˆå†»ç»“SAMä¸»å¹²ï¼Œæ¨èï¼š5-10ï¼‰')
    parser.add_argument('--stage1_learning_rate', type=float, default=1e-4,
                       help='é˜¶æ®µä¸€å­¦ä¹ ç‡ï¼ˆå†»ç»“é˜¶æ®µï¼Œæ¨èï¼š1e-4ï¼Œå¿«é€Ÿå­¦ä¹ æ–°å‚æ•°ï¼‰')
    parser.add_argument('--stage2_lr_sam', type=float, default=1e-6,
                       help='é˜¶æ®µäºŒSAMä¸»å¹²å­¦ä¹ ç‡ï¼ˆè§£å†»é˜¶æ®µï¼Œæ¨èï¼š1e-6ï¼Œæä½å­¦ä¹ ç‡ç²¾ä¿®ï¼‰')
    parser.add_argument('--stage2_lr_panet', type=float, default=1e-5,
                       help='é˜¶æ®µäºŒPANetå­¦ä¹ ç‡ï¼ˆè§£å†»é˜¶æ®µï¼Œæ¨èï¼š1e-5ï¼Œä¸­ç­‰å­¦ä¹ ç‡ï¼‰')
    parser.add_argument('--stage2_lr_head', type=float, default=1e-5,
                       help='é˜¶æ®µäºŒåˆ†å‰²å¤´å­¦ä¹ ç‡ï¼ˆè§£å†»é˜¶æ®µï¼Œæ¨èï¼š1e-5ï¼Œä¸­ç­‰å­¦ä¹ ç‡ï¼‰')
    
    # æ•°æ®å‚æ•°
    parser.add_argument('--image_size', type=int, nargs=2, default=[512, 512],
                       help='å›¾åƒå°ºå¯¸ (H W)ï¼ˆæ¨èï¼š512x512ï¼Œå¹³è¡¡æ€§èƒ½å’Œæ˜¾å­˜ï¼‰')
    parser.add_argument('--num_workers', type=int, default=0,
                       help='æ•°æ®åŠ è½½å™¨å·¥ä½œè¿›ç¨‹æ•°ï¼ˆé»˜è®¤ï¼š0ï¼Œé¿å…å¤šè¿›ç¨‹é—®é¢˜ï¼‰')
    parser.add_argument('--use_augmentation', action='store_true',
                       help='ä½¿ç”¨æ•°æ®å¢å¼ºï¼ˆå·²é»˜è®¤å¯ç”¨ï¼Œæ­¤å‚æ•°ä¿ç•™ç”¨äºå‘åå…¼å®¹ï¼‰')
    parser.add_argument('--split_file_dir', type=str, default='database/database_split',
                       help='æ•°æ®é›†åˆ†å‰²æ–‡ä»¶ç›®å½•')
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument('--feature_dim', type=int, default=256,
                       help='ç‰¹å¾ç»´åº¦')
    parser.add_argument('--use_hq', action='store_true',
                       help='ä½¿ç”¨HQSAM')
    parser.add_argument('--use_sam_features', action='store_true',
                       help='ä½¿ç”¨SAMç‰¹å¾ï¼ˆPANetæ¨¡å‹ï¼‰')
    parser.add_argument('--use_prompts', action='store_true',
                       help='ä½¿ç”¨çœŸå®Promptç”Ÿæˆï¼ˆåŸºäºåˆ†å‰²æ©ç ç”Ÿæˆç‚¹å’Œè¾¹ç•Œæ¡†ï¼‰')
    
    # å…¶ä»–å‚æ•°
    parser.add_argument('--resume', type=str, default=None,
                       help='æ¢å¤è®­ç»ƒçš„æ£€æŸ¥ç‚¹è·¯å¾„')
    parser.add_argument('--config_file', type=str, default=None,
                       help='é…ç½®æ–‡ä»¶è·¯å¾„')
    
    args = parser.parse_args()
    
    # åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„è¾“å‡ºæ–‡ä»¶å¤¹
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_dir = f'shared/outputs/training_{timestamp}'
    # åˆ›å»ºä¸“é—¨çš„checkpointæ–‡ä»¶å¤¹ï¼ŒæŒ‰æ—¶é—´æˆ³å‘½å
    checkpoint_dir = f'shared/checkpoints/training_{timestamp}'
    os.makedirs(output_dir, exist_ok=True)
    os.makedirs(checkpoint_dir, exist_ok=True)
    
    # é™é»˜è®¾ç½®æ—¥å¿—
    logger = setup_logging(output_dir)
    
    # è®¾ç½®è®¾å¤‡
    device = setup_device(args.device)
    
    # è®¾ç½®PyTorchç¯å¢ƒå˜é‡ä»¥æŠ‘åˆ¶è­¦å‘Š
    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'
    

    
    # æŠ‘åˆ¶PyTorchå†…éƒ¨è­¦å‘Š
    import warnings
    warnings.filterwarnings("ignore", category=UserWarning, module="torch.nn.modules.module")
    warnings.filterwarnings("ignore", category=UserWarning, module="torch.optim.lr_scheduler")
    
    # é™é»˜åŠ è½½é…ç½®
    if args.config_file and os.path.exists(args.config_file):
        with open(args.config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
    else:
        config = CardiacConfig().get_model_config(args.model_type)
    
    # æ›´æ–°é…ç½®
    config.update({
        'model_type': args.model_type,
        'epochs': args.epochs,
        'batch_size': args.batch_size,
        'accumulate_steps': args.accumulate_steps,
        'learning_rate': args.learning_rate,
        'weight_decay': args.weight_decay,
        'image_size': tuple(args.image_size),
        'feature_dim': args.feature_dim,
        'use_hq': args.use_hq,
        'use_sam_features': args.use_sam_features,
        'use_prompts': args.use_prompts,
        'use_amp': args.use_amp,
        'use_checkpoint': args.use_checkpoint,
        'output_dir': output_dir,
        'checkpoint_dir': checkpoint_dir,
        'log_dir': os.path.join(output_dir, 'logs')
    })
    
    # é™é»˜é…ç½®
    if args.use_two_stage:
        config.update({
            'use_two_stage': True,
            'stage1_epochs': args.stage1_epochs,
            'stage1_learning_rate': args.stage1_learning_rate,
            'stage2_lr_sam': args.stage2_lr_sam,
            'stage2_lr_panet': args.stage2_lr_panet,
            'stage2_lr_head': args.stage2_lr_head
        })
    
    # é™é»˜ä¿å­˜é…ç½®
    config_file = os.path.join(output_dir, 'config.json')
    with open(config_file, 'w', encoding='utf-8') as f:
        json.dump(config, f, indent=2, ensure_ascii=False)
    
    try:
        # é™é»˜åˆ›å»ºæ•°æ®å’Œæ¨¡å‹
        dataloader = create_cardiac_dataloader(
            data_root=args.data_root,
            batch_size=args.batch_size,
            num_workers=args.num_workers,
            image_size=tuple(args.image_size),
            use_augmentation=True,  # é»˜è®¤å¯ç”¨æ•°æ®å¢å¼ºï¼Œæé«˜æ¨¡å‹æ³›åŒ–èƒ½åŠ›
            use_prompts=args.use_prompts,
            split_file_dir=args.split_file_dir
        )
        
        train_loader = dataloader.create_dataloader('train')
        val_loader = dataloader.create_dataloader('validation')
        model = create_model(args.model_type, config, device)
        
        # é™é»˜å‡†å¤‡è®­ç»ƒ
        verification_results = verify_fixes(model, device, logger)
        if args.use_two_stage:
            setup_two_stage_training(model, config, device)
        
        trainer = create_trainer(
            model=model,
            model_type=args.model_type,
            train_loader=train_loader,
            val_loader=val_loader,
            config=config,
            device=device,
            checkpoint_dir=checkpoint_dir
        )
        
        if args.resume and os.path.exists(args.resume):
            trainer.load_checkpoint(args.resume)
        
        if args.use_classification_training:
            # æ‰§è¡Œä¸‰é˜¶æ®µåˆ†ç±»è®­ç»ƒ
            training_results = execute_classification_training(model, train_loader, val_loader, config, device, logger, output_dir)
        elif args.use_two_stage:
            # æ‰§è¡Œä¸¤é˜¶æ®µè®­ç»ƒ
            training_results = execute_two_stage_training(trainer, config, logger)
        else:
            # æ‰§è¡Œæ ‡å‡†è®­ç»ƒ
            training_results = trainer.train()
        
        # ä¿å­˜è®­ç»ƒç»“æœ
        results_file = os.path.join(output_dir, 'training_results.json')
        # è½¬æ¢è®­ç»ƒç»“æœä¸ºJSONå¯åºåˆ—åŒ–æ ¼å¼
        serializable_results = {}
        for key, value in training_results.items():
            if isinstance(value, list):
                serializable_results[key] = []
                for item in value:
                    if isinstance(item, dict):
                        # å¤„ç†å­—å…¸ç±»å‹
                        serializable_item = {}
                        for k, v in item.items():
                            if isinstance(v, (int, float, str, bool)) or v is None:
                                serializable_item[k] = v
                            elif isinstance(v, torch.Tensor):
                                serializable_item[k] = v.item() if v.numel() == 1 else v.tolist()
                            else:
                                serializable_item[k] = str(v)
                        serializable_results[key].append(serializable_item)
                    else:
                        serializable_results[key].append(str(item))
            elif isinstance(value, dict):
                # å¤„ç†å­—å…¸ç±»å‹
                serializable_results[key] = {}
                for k, v in value.items():
                    if isinstance(v, (int, float, str, bool)) or v is None:
                        serializable_results[key][k] = v
                    elif isinstance(v, torch.Tensor):
                        serializable_results[key][k] = v.item() if v.numel() == 1 else v.tolist()
                    else:
                        serializable_results[key][k] = str(v)
            else:
                serializable_results[key] = str(value)
        
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(serializable_results, f, indent=2, ensure_ascii=False)
        logger.debug(f"è®­ç»ƒç»“æœå·²ä¿å­˜: {results_file}")
        
        logger.debug("è®­ç»ƒå®Œæˆï¼")
        
    except Exception as e:
        logger.error(f"è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise


if __name__ == "__main__":
    main()
